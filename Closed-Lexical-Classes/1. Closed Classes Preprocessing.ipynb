{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8d7b92",
   "metadata": {},
   "source": [
    "# Goal: Investigate birth and death among closed classes of words\n",
    "Load and Pre-Process   \n",
    "1. Load all the gzipped ngrams data into the notebook  \n",
    "2. Pre-process Google Ngrams database so that there is only the following [Google Tags](https://books.google.com/ngrams/info)\n",
    "    - _PRON_\tpronoun\n",
    "    - _DET_\tdeterminer or article\n",
    "    - _ADP_\tan adposition: either a preposition or a postposition\n",
    "    - _CONJ_\tconjunction\n",
    "    - _PRT_\tparticle  \n",
    "    (These tags can only be appended to a word (she_PRON), no stand alones (\\_PRON\\_))\n",
    "3. Save as JSON file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2901e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb06cc9",
   "metadata": {},
   "source": [
    "## Load and pre-process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf7cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "#For the Google POS tagging\n",
    "underscore = re.compile('_{1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7d61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "PUNCTUATION = set(char for char in string.punctuation).union({'“','”'})\n",
    "DIGITS = set(string.digits)\n",
    "VOWELS = set(\"aeiouyAEIOUY\")\n",
    "#Excluding '_' (underscore) from DASHES precludes the tagged 1grams \"_NOUN\", add it to also include the tagged 1grams\n",
    "DASHES = {'—','–','—','―','‒','-','_'}\n",
    "PUNCTUATION.difference_update(DASHES)\n",
    "STOPS = PUNCTUATION.union(DIGITS)\n",
    "GOOGLE_TAGS = {'PRON','DET','ADP','CONJ','PRT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3316928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_gzip(directory,file_path):\n",
    "    with gzip.open(directory+file_path,'r') as f_in:\n",
    "        rows = [x.decode('utf8').strip() for x in f_in.readlines()]\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bf620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2tuple(string):\n",
    "    year,match_count,volume_count = tuple(string.split(','))\n",
    "    return int(year),int(match_count),int(volume_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849b81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(dictionary,directory,file_path):\n",
    "    output = file_path+'.json'\n",
    "    if len(dictionary)>0:\n",
    "        with open(directory+output, 'w') as f_out:\n",
    "            json.dump(dictionary, f_out)\n",
    "        print('SAVED: ',output,len(dictionary))\n",
    "    else:\n",
    "        print('unigram dict empty',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f8fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_tests(unigram):\n",
    "    #Checks each character in the unigram against the characters in the STOP set. (character level filtering) - no punctuation or digits allowed\n",
    "    if set(unigram).intersection(STOPS):\n",
    "        return False\n",
    "    \n",
    "    #must have a vowel (presupposes that it must also have a letter of the alphabet inside)\n",
    "    if not set(unigram).intersection(VOWELS):\n",
    "        return False #Rewrite the alphabet one, i think this is better\n",
    "    \n",
    "    #Words cannot start or end with dashes\n",
    "    if unigram[0] in DASHES or unigram[-1] in DASHES:\n",
    "        return False\n",
    "    \n",
    "    #Exclude words with more than one underscore, can make this != to only include tagged words\n",
    "    if len(underscore.findall(unigram))>1:\n",
    "        return False\n",
    "    \n",
    "    #must have 0 non-english letters\n",
    "    test = unidecode(unigram, errors='replace')\n",
    "    if test != unigram:\n",
    "        return False\n",
    "    \n",
    "    #Can implement more tests here if you need to do more filtering\n",
    "    \n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b3f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ngrams(directory,file_path):\n",
    "    \n",
    "    rows = open_gzip(directory,file_path)\n",
    "    ngram_dict = dict()\n",
    "\n",
    "    #This implementation uses {1gram:{year:match_count ...} ...}\n",
    "    for row in tqdm(rows):\n",
    "        columns = row.split('\\t')\n",
    "        #unigram is the first entry, the rest of the entries are of the form year,match_count,volume_count\\t n times, where n is variable each line\n",
    "        \n",
    "        unigram = columns[0]\n",
    "        if len(underscore.findall(unigram))==1: #One and only one underscore allowed\n",
    "            word_tag = underscore.split(unigram) # list of [word,tag]\n",
    "            #checks if tag is Google tag\n",
    "            if word_tag[1] in GOOGLE_TAGS:\n",
    "                #Removes the tag before processing unigram string\n",
    "                unigram = word_tag[0].lower().strip()+'_'+word_tag[1]\n",
    "                if unigram_tests(unigram):\n",
    "                    #Parse the new entry and create a list of records in form [...[year, match_count]...]\n",
    "                    records = dict()\n",
    "                    #the first entry in columns is word so that is exluded\n",
    "                    for entry in columns[1:]:\n",
    "                        year,match_count,volume_count = csv2tuple(str(entry))\n",
    "                        if year>1800 and volume_count>1:\n",
    "                            records[year] = match_count\n",
    "\n",
    "                    #Modify the dictionary if new entry is already there, else just add it as a new unigram:records to the dict\n",
    "                    if unigram in ngram_dict.keys():\n",
    "                        #accessing the ngram dictionary and seeing if each year is present, if so add match count, else add a new record entry to the dictionary.\n",
    "                        for yr, match_ct in records.items(): #each record should be of the form {year, match_count}\n",
    "                            #If the year in the new record is in the dict for this 1gram, then find where it is.\n",
    "                            if yr in ngram_dict[unigram].keys():\n",
    "                                ngram_dict[unigram][yr] += match_ct\n",
    "                            else:\n",
    "                                #This just adds the record to the end, will need to sort later\n",
    "                                ngram_dict[unigram][yr] = match_ct\n",
    "                    else:\n",
    "                        ngram_dict[unigram] = records\n",
    "    \n",
    "    #Save as JSON\n",
    "    save_json(ngram_dict,directory,file_path[:-3]+'_CLOSED_CLASSES')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078e1a7",
   "metadata": {},
   "source": [
    "## Run Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a030e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2396510/2396510 [00:08<00:00, 273583.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00000-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3100658/3100658 [00:11<00:00, 272696.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00015-of-00024_CLOSED_CLASSES.json 13055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3109631/3109631 [00:14<00:00, 210005.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00009-of-00024_CLOSED_CLASSES.json 4368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3365531/3365531 [00:12<00:00, 268541.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00010-of-00024_CLOSED_CLASSES.json 12317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3467821/3467821 [00:17<00:00, 196730.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00022-of-00024_CLOSED_CLASSES.json 33454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3384057/3384057 [00:17<00:00, 197203.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00019-of-00024_CLOSED_CLASSES.json 72093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375570/3375570 [00:11<00:00, 304435.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00005-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3103866/3103866 [00:10<00:00, 303158.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00006-of-00024_CLOSED_CLASSES.json 16626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3071926/3071926 [00:16<00:00, 183288.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00021-of-00024_CLOSED_CLASSES.json 41723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3402459/3402459 [00:10<00:00, 321199.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00013-of-00024_CLOSED_CLASSES.json 3739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375649/3375649 [00:21<00:00, 154702.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00016-of-00024_CLOSED_CLASSES.json 123093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3081673/3081673 [00:08<00:00, 374533.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00003-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3377697/3377697 [00:10<00:00, 321879.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00004-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3118263/3118263 [00:18<00:00, 166394.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00018-of-00024_CLOSED_CLASSES.json 36568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4149670/4149670 [00:29<00:00, 141692.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00023-of-00024_CLOSED_CLASSES.json 122872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00006-of-00024-COMPLETE.json_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3386487/3386487 [00:14<00:00, 239002.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00011-of-00024_CLOSED_CLASSES.json 4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3408143/3408143 [00:16<00:00, 210132.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00008-of-00024_CLOSED_CLASSES.json 2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3392643/3392643 [01:05<00:00, 51742.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00014-of-00024_CLOSED_CLASSES.json 15740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3345476/3345476 [00:12<00:00, 259200.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00001-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3315859/3315859 [00:13<00:00, 241878.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00002-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403219/3403219 [00:16<00:00, 206694.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00017-of-00024_CLOSED_CLASSES.json 20180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3135145/3135145 [00:13<00:00, 225744.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00012-of-00024_CLOSED_CLASSES.json 12206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3427775/3427775 [00:18<00:00, 186505.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00020-of-00024_CLOSED_CLASSES.json 77955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3384843/3384843 [00:13<00:00, 250183.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00007-of-00024_CLOSED_CLASSES.json 9092\n",
      "CPU times: user 11min 17s, sys: 1min 27s, total: 12min 44s\n",
      "Wall time: 14min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "directory = './Ngrams/'\n",
    "files = os.listdir(directory)\n",
    "for file_path in files:\n",
    "    if '.gz' in file_path:\n",
    "        preprocess_ngrams(directory,file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
