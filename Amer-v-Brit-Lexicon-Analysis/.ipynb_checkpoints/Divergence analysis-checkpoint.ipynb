{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divergence Analysis\n",
    "\n",
    "### Ideas:\n",
    "\n",
    "- Get some nice plots\n",
    "- Do some nice statistics\n",
    "- Do some nice set theoretic analyses\n",
    "- ARIMA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "#import os\n",
    "#import statistics\n",
    "#from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "amer_directory = '../Ngrams/amer_unigram_data/'\n",
    "brit_directory = '../Ngrams/brit_unigram_data/'\n",
    "\n",
    "def open_json(directory,file_path):\n",
    "    with open(directory+file_path,'r') as f:\n",
    "        json_dictionary = json.load(f)\n",
    "        f.close()\n",
    "    return json_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1801-1850 Set Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRIT_1801_1850_STEP1 = open_json(brit_directory,'LEXICON_1801-1850_STEP1.json')\n",
    "AMER_1801_1850_STEP1 = open_json(amer_directory,'LEXICON_1801-1850_STEP1.json')\n",
    "\n",
    "brit_1801_1850_s1 = set(BRIT_1801_1850_STEP1.keys())\n",
    "amer_1801_1850_s1 = set(AMER_1801_1850_STEP1.keys())\n",
    "\n",
    "intersection_1801_1850 = brit_1801_1850_s1.intersection(amer_1801_1850_s1)\n",
    "amer_unique_1801_1850_s1 = amer_1801_1850_s1.difference(intersection_1801_1850)\n",
    "brit_unique_1801_1850_s1 = brit_1801_1850_s1.difference(intersection_1801_1850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106474, 37196, 37694)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brit_1801_1850_s1),len(intersection_1801_1850),len(amer_1801_1850_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 69278)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amer_unique_1801_1850_s1),len(brit_unique_1801_1850_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amer_unique_1801_1850_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brit_unique_1801_1850_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1851-1900 Set Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRIT_1851_1900_STEP1 = open_json(brit_directory,'LEXICON_1851-1900_STEP1.json')\n",
    "AMER_1851_1900_STEP1 = open_json(amer_directory,'LEXICON_1851-1900_STEP1.json')\n",
    "\n",
    "brit_1851_1900_s1 = set(BRIT_1851_1900_STEP1.keys())\n",
    "amer_1851_1900_s1 = set(AMER_1851_1900_STEP1.keys())\n",
    "\n",
    "intersection_1851_1900 = brit_1851_1900_s1.intersection(amer_1851_1900_s1)\n",
    "amer_unique_1851_1900_s1 = amer_1851_1900_s1.difference(intersection_1851_1900)\n",
    "brit_unique_1851_1900_s1 = brit_1851_1900_s1.difference(intersection_1851_1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244666, 183790, 230103)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brit_1851_1900_s1),len(intersection_1851_1900),len(amer_1851_1900_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46313, 60876)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amer_unique_1851_1900_s1),len(brit_unique_1851_1900_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amer_unique_1851_1900_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brit_unique_1851_1900_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1901-1950 Set Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRIT_1901_1950_STEP1 = open_json(brit_directory,'LEXICON_1901-1950_STEP1.json')\n",
    "AMER_1901_1950_STEP1 = open_json(amer_directory,'LEXICON_1901-1950_STEP1.json')\n",
    "\n",
    "brit_1901_1950_s1 = set(BRIT_1901_1950_STEP1.keys())\n",
    "amer_1901_1950_s1 = set(AMER_1901_1950_STEP1.keys())\n",
    "\n",
    "intersection_1901_1950 = brit_1901_1950_s1.intersection(amer_1901_1950_s1)\n",
    "amer_unique_1901_1950_s1 = amer_1901_1950_s1.difference(intersection_1901_1950)\n",
    "brit_unique_1901_1950_s1 = brit_1901_1950_s1.difference(intersection_1901_1950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174324, 164436, 451000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brit_1901_1950_s1),len(intersection_1901_1950),len(amer_1901_1950_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286564, 9888)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amer_unique_1901_1950_s1),len(brit_unique_1901_1950_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amer_unique_1901_1950_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brit_unique_1901_1950_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1951-2000 Set Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRIT_1951_2000_STEP1 = open_json(brit_directory,'LEXICON_1951-2000_STEP1.json')\n",
    "AMER_1951_2000_STEP1 = open_json(amer_directory,'LEXICON_1951-2000_STEP1.json')\n",
    "\n",
    "brit_1951_2000_s1 = set(BRIT_1951_2000_STEP1.keys())\n",
    "amer_1951_2000_s1 = set(AMER_1951_2000_STEP1.keys())\n",
    "\n",
    "intersection_1951_2000 = brit_1951_2000_s1.intersection(amer_1951_2000_s1)\n",
    "amer_unique_1951_2000_s1 = amer_1951_2000_s1.difference(intersection_1951_2000)\n",
    "brit_unique_1951_2000_s1 = brit_1951_2000_s1.difference(intersection_1951_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281984, 268910, 777075)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brit_1951_2000_s1),len(intersection_1951_2000),len(amer_1951_2000_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508165, 13074)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amer_unique_1951_2000_s1),len(brit_unique_1951_2000_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amer_unique_1951_2000_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brit_unique_1951_2000_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "amer_unique = amer_unique_1951_2000_s1.intersection(amer_unique_1901_1950_s1,amer_unique_1851_1900_s1,amer_unique_1801_1850_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "brit_unique = brit_unique_1951_2000_s1.intersection(brit_unique_1901_1950_s1,brit_unique_1851_1900_s1,brit_unique_1801_1850_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 147)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amer_unique),len(brit_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abeel_NOUN',\n",
       " 'agawam_NOUN',\n",
       " 'agreea_NOUN',\n",
       " 'alatamaha_NOUN',\n",
       " 'amendatory_ADJ',\n",
       " 'amendatory_NOUN',\n",
       " 'bioren_NOUN',\n",
       " 'boudinot_NOUN',\n",
       " 'chenango_NOUN',\n",
       " 'chilicothe_NOUN',\n",
       " 'deposeth_NOUN',\n",
       " 'dutchess_ADJ',\n",
       " 'edenton_NOUN',\n",
       " 'ferriage_NOUN',\n",
       " 'governeur_NOUN',\n",
       " 'gpd_NOUN',\n",
       " 'harrisburgh_NOUN',\n",
       " 'haverstraw_NOUN',\n",
       " 'hopkinton_NOUN',\n",
       " 'hunterdon_NOUN',\n",
       " 'inhab_ADJ',\n",
       " 'kaskaskias_NOUN',\n",
       " 'kennebeck_NOUN',\n",
       " 'kennebunk_NOUN',\n",
       " 'ladelphia_NOUN',\n",
       " 'lansingburgh_NOUN',\n",
       " 'lewistown_NOUN',\n",
       " 'lumbia_NOUN',\n",
       " 'machias_NOUN',\n",
       " 'massac_NOUN',\n",
       " 'medfield_NOUN',\n",
       " 'mohegan_NOUN',\n",
       " 'natches_NOUN',\n",
       " 'necticut_NOUN',\n",
       " 'newhampshire_NOUN',\n",
       " 'newjersey_NOUN',\n",
       " 'newlondon_NOUN',\n",
       " 'neworleans_NOUN',\n",
       " 'northamerica_NOUN',\n",
       " 'northcarolina_NOUN',\n",
       " 'oconee_NOUN',\n",
       " 'olence_NOUN',\n",
       " 'onondago_NOUN',\n",
       " 'pascalis_NOUN',\n",
       " 'pittstown_NOUN',\n",
       " 'puking_NOUN',\n",
       " 'purviance_NOUN',\n",
       " 'rhodeisland_NOUN',\n",
       " 'rockbridge_NOUN',\n",
       " 'rolina_NOUN',\n",
       " 'sachusetts_NOUN',\n",
       " 'saluda_NOUN',\n",
       " 'schoharie_NOUN',\n",
       " 'segars_NOUN',\n",
       " 'shajl_VERB',\n",
       " 'shawanese_NOUN',\n",
       " 'simsbury_NOUN',\n",
       " 'sollowing_VERB',\n",
       " 'southcarolina_NOUN',\n",
       " 'stoddert_NOUN',\n",
       " 'stratham_NOUN',\n",
       " 'surther_VERB',\n",
       " 'swartwout_NOUN',\n",
       " 'tennesse_NOUN',\n",
       " 'ticut_NOUN',\n",
       " 'truxton_NOUN',\n",
       " 'varnum_NOUN',\n",
       " 'warrantee_NOUN',\n",
       " 'weathersfield_NOUN',\n",
       " 'whitestown_NOUN',\n",
       " 'yadkin_NOUN',\n",
       " 'yea_NUM'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amer_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aberlady_NOUN',\n",
       " 'accompte_NOUN',\n",
       " 'addingham_NOUN',\n",
       " 'alphage_NOUN',\n",
       " 'annuatim_X',\n",
       " 'aprilis_X',\n",
       " 'aucht_NOUN',\n",
       " 'avourable_ADJ',\n",
       " 'bassishaw_NOUN',\n",
       " 'bathwick_NOUN',\n",
       " 'befoir_ADP',\n",
       " 'begyn_VERB',\n",
       " 'benefice_ADP',\n",
       " 'boxhill_NOUN',\n",
       " 'burgi_X',\n",
       " 'bwlch_NOUN',\n",
       " 'cambuskenneth_NOUN',\n",
       " 'campvere_NOUN',\n",
       " 'cawsand_NOUN',\n",
       " 'cerrig_NOUN',\n",
       " 'chalder_NOUN',\n",
       " 'chapelries_NOUN',\n",
       " 'clipstone_NOUN',\n",
       " 'coldham_NOUN',\n",
       " 'colourmen_NOUN',\n",
       " 'contynue_VERB',\n",
       " 'courtown_NOUN',\n",
       " 'croftes_NOUN',\n",
       " 'dalswinton_NOUN',\n",
       " 'dapifer_NOUN',\n",
       " 'decern_VERB',\n",
       " 'drummore_NOUN',\n",
       " 'dunging_NOUN',\n",
       " 'dunstanville_NOUN',\n",
       " 'easingwold_NOUN',\n",
       " 'edwardi_X',\n",
       " 'eglwys_NOUN',\n",
       " 'exciseable_ADJ',\n",
       " 'favourites_VERB',\n",
       " 'feuars_NOUN',\n",
       " 'feued_VERB',\n",
       " 'fiars_NOUN',\n",
       " 'flixton_NOUN',\n",
       " 'fornham_NOUN',\n",
       " 'fourtie_NUM',\n",
       " 'galfrid_NOUN',\n",
       " 'glatton_NOUN',\n",
       " 'gwennap_NOUN',\n",
       " 'haughs_NOUN',\n",
       " 'hawise_NOUN',\n",
       " 'highworth_NOUN',\n",
       " 'hildersham_NOUN',\n",
       " 'hilsea_NOUN',\n",
       " 'hitcham_NOUN',\n",
       " 'holbourne_NOUN',\n",
       " 'humberston_NOUN',\n",
       " 'humbie_NOUN',\n",
       " 'iabour_NOUN',\n",
       " 'infeft_VERB',\n",
       " 'infeftment_NOUN',\n",
       " 'inspeximus_NOUN',\n",
       " 'kennoway_NOUN',\n",
       " 'kilmaine_NOUN',\n",
       " 'kinfauns_NOUN',\n",
       " 'kircudbright_NOUN',\n",
       " 'kirkmichael_NOUN',\n",
       " 'lanthony_NOUN',\n",
       " 'lexden_NOUN',\n",
       " 'llandilo_NOUN',\n",
       " 'madocks_NOUN',\n",
       " 'mapletoft_NOUN',\n",
       " 'measham_NOUN',\n",
       " 'meigle_NOUN',\n",
       " 'merks_VERB',\n",
       " 'methwold_NOUN',\n",
       " 'micklegate_NOUN',\n",
       " 'modbury_NOUN',\n",
       " 'monopolising_NOUN',\n",
       " 'mornynge_NOUN',\n",
       " 'multure_NOUN',\n",
       " 'murdac_NOUN',\n",
       " 'nelthorpe_NOUN',\n",
       " 'nemorum_NOUN',\n",
       " 'netherbow_NOUN',\n",
       " 'newbottle_NOUN',\n",
       " 'newenden_NOUN',\n",
       " 'northwold_NOUN',\n",
       " 'ochtertyre_NOUN',\n",
       " 'ombersley_NOUN',\n",
       " 'oxendon_NOUN',\n",
       " 'pairt_VERB',\n",
       " 'parliamentum_NOUN',\n",
       " 'paroch_NOUN',\n",
       " 'patrington_NOUN',\n",
       " 'pechell_NOUN',\n",
       " 'pemb_NOUN',\n",
       " 'pencaitland_NOUN',\n",
       " 'penmaen_NOUN',\n",
       " 'pittenweem_NOUN',\n",
       " 'portioner_NOUN',\n",
       " 'portioners_NOUN',\n",
       " 'portsoy_NOUN',\n",
       " 'prebendal_NOUN',\n",
       " 'presentlie_NOUN',\n",
       " 'presteign_NOUN',\n",
       " 'protulit_X',\n",
       " 'provyde_VERB',\n",
       " 'quhen_ADV',\n",
       " 'quhen_X',\n",
       " 'quhilk_VERB',\n",
       " 'repayred_VERB',\n",
       " 'ridware_NOUN',\n",
       " 'righthon_NOUN',\n",
       " 'sedgmoor_NOUN',\n",
       " 'shacklewell_NOUN',\n",
       " 'soche_ADJ',\n",
       " 'southover_NOUN',\n",
       " 'speciallie_NOUN',\n",
       " 'spithead_VERB',\n",
       " 'splendour_ADV',\n",
       " 'stretham_NOUN',\n",
       " 'teinds_NOUN',\n",
       " 'thame_PRON',\n",
       " 'thame_VERB',\n",
       " 'thatcham_NOUN',\n",
       " 'thornham_NOUN',\n",
       " 'thornhaugh_NOUN',\n",
       " 'thyngs_NOUN',\n",
       " 'tillicoultry_NOUN',\n",
       " 'tinwald_NOUN',\n",
       " 'tokenhouse_NOUN',\n",
       " 'traeth_NOUN',\n",
       " 'ulbster_NOUN',\n",
       " 'unfavour_ADJ',\n",
       " 'uponthames_NOUN',\n",
       " 'upontweed_NOUN',\n",
       " 'upwell_NOUN',\n",
       " 'warblington_NOUN',\n",
       " 'warnford_NOUN',\n",
       " 'whittlebury_NOUN',\n",
       " 'widmore_NOUN',\n",
       " 'wilsden_NOUN',\n",
       " 'winchelsey_NOUN',\n",
       " 'wingerworth_NOUN',\n",
       " 'wolsingham_NOUN',\n",
       " 'woodchurch_NOUN',\n",
       " 'woolled_VERB'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brit_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(directory, t_start, t_end, t_step):\n",
    "    lexicon = dict()\n",
    "    total_usage = 0\n",
    "    files = os.listdir(directory)\n",
    "    for file_name in files:\n",
    "        if '-COMPLETE.json' in file_name:\n",
    "            ngrams = open_json(directory,file_name)\n",
    "            print('Opened ',file_name)\n",
    "            unigram_dict, years = normalize(ngrams, t_start, t_end)\n",
    "            del ngrams\n",
    "            print('Normalized')\n",
    "            if t_step>1:\n",
    "                unigram_dict, years = smoothing(unigram_dict, years, t_step)\n",
    "                print('Smoothed')\n",
    "            #We only get a sublexicon because each file is only a single piece of the full lexicon.\n",
    "            sublexicon, usage = return_sublexicon(unigram_dict)\n",
    "            del unigram_dict\n",
    "            print('Got sublexicon')\n",
    "            lexicon.update(sublexicon)\n",
    "            total_usage+=usage\n",
    "            del sublexicon #frees up memory for next round, before the compiler gets to it.\n",
    "    \n",
    "    print('Adding frequency')\n",
    "    lexicon = add_frequency(lexicon, total_usage)\n",
    "    \n",
    "    save_json(lexicon,directory,str('LEXICON_'+str(years[0])+'-'+str(years[-1])+'_STEP'+str(t_step)))\n",
    "    print('Frequency added. Lexicon Saved.')\n",
    "    \n",
    "    return lexicon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:evol-ling]",
   "language": "python",
   "name": "conda-env-evol-ling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
