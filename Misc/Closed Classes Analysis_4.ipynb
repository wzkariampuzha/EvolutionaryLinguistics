{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8d7b92",
   "metadata": {},
   "source": [
    "# Goal: Investigate birth and death among closed classes of words\n",
    "1. Load and Pre-Process  \n",
    "    a. Load all the gzipped ngrams data into the notebook  \n",
    "    b. Pre-process Google Ngrams database so that there is only the following [Google Tags](https://books.google.com/ngrams/info)\n",
    "        - _PRON_\tpronoun\n",
    "        - _DET_\tdeterminer or article\n",
    "        - _ADP_\tan adposition: either a preposition or a postposition\n",
    "        - _CONJ_\tconjunction\n",
    "        - _PRT_\tparticle  \n",
    "        (These tags can only be appended to a word (she_PRON), no stand alones (\\_PRON\\_))\n",
    "    c. Save as JSON file  \n",
    "~  \n",
    "2. Investigate  \n",
    "    a. Load in pre-processed JSON Files  \n",
    "    b. Normalize the dictionary to have standard width  \n",
    "    c. Smooth the data (rolling average)  \n",
    "    d. Isolate years of word birth and death {unigram:\\[year1, year2, ...\\]   \n",
    "    e. Save Birth and Death dictionaries separately as JSON files  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2901e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb06cc9",
   "metadata": {},
   "source": [
    "## (1) Load and pre-process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf7cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "#For the Google POS tagging\n",
    "underscore = re.compile('_{1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7d61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "PUNCTUATION = set(char for char in string.punctuation).union({'“','”'})\n",
    "DIGITS = set(string.digits)\n",
    "VOWELS = set(\"aeiouyAEIOUY\")\n",
    "#Excluding '_' (underscore) from DASHES precludes the tagged 1grams \"_NOUN\", add it to also include the tagged 1grams\n",
    "DASHES = {'—','–','—','―','‒','-','_'}\n",
    "PUNCTUATION.difference_update(DASHES)\n",
    "STOPS = PUNCTUATION.union(DIGITS)\n",
    "GOOGLE_TAGS = {'PRON','DET','ADP','CONJ','PRT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3316928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_gzip(directory,file_path):\n",
    "    with gzip.open(directory+file_path,'r') as f_in:\n",
    "        rows = [x.decode('utf8').strip() for x in f_in.readlines()]\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bf620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2tuple(string):\n",
    "    year,match_count,volume_count = tuple(string.split(','))\n",
    "    return int(year),int(match_count),int(volume_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849b81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(dictionary,directory,file_path):\n",
    "    output = file_path+'.json'\n",
    "    if len(dictionary)>0:\n",
    "        with open(directory+output, 'w') as f_out:\n",
    "            json.dump(dictionary, f_out)\n",
    "        print('SAVED: ',output,len(dictionary))\n",
    "    else:\n",
    "        print('unigram dict empty',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f8fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_tests(unigram):\n",
    "    #Checks each character in the unigram against the characters in the STOP set. (character level filtering) - no punctuation or digits allowed\n",
    "    if set(unigram).intersection(STOPS):\n",
    "        return False\n",
    "    \n",
    "    #must have a vowel (presupposes that it must also have a letter of the alphabet inside)\n",
    "    if not set(unigram).intersection(VOWELS):\n",
    "        return False #Rewrite the alphabet one, i think this is better\n",
    "    \n",
    "    #Words cannot start or end with dashes\n",
    "    if unigram[0] in DASHES or unigram[-1] in DASHES:\n",
    "        return False\n",
    "    \n",
    "    #Exclude words with more than one underscore, can make this != to only include tagged words\n",
    "    if len(underscore.findall(unigram))>1:\n",
    "        return False\n",
    "    \n",
    "    #must have 0 non-english letters\n",
    "    test = unidecode(unigram, errors='replace')\n",
    "    if test != unigram:\n",
    "        return False\n",
    "    \n",
    "    #Can implement more tests here if you need to do more filtering\n",
    "    \n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b3f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ngrams(directory,file_path):\n",
    "    \n",
    "    rows = open_gzip(directory,file_path)\n",
    "    ngram_dict = dict()\n",
    "\n",
    "    #This implementation uses {1gram:{year:match_count ...} ...}\n",
    "    for row in tqdm(rows):\n",
    "        columns = row.split('\\t')\n",
    "        #unigram is the first entry, the rest of the entries are of the form year,match_count,volume_count\\t n times, where n is variable each line\n",
    "        \n",
    "        unigram = columns[0]\n",
    "        if len(underscore.findall(unigram))==1: #One and only one underscore allowed\n",
    "            word_tag = underscore.split(unigram) # list of [word,tag]\n",
    "            #checks if tag is Google tag\n",
    "            if word_tag[1] in GOOGLE_TAGS:\n",
    "                #Removes the tag before processing unigram string\n",
    "                unigram = word_tag[0].lower().strip()+'_'+word_tag[1]\n",
    "                if unigram_tests(unigram):\n",
    "                    #Parse the new entry and create a list of records in form [...[year, match_count]...]\n",
    "                    records = dict()\n",
    "                    #the first entry in columns is word so that is exluded\n",
    "                    for entry in columns[1:]:\n",
    "                        year,match_count,volume_count = csv2tuple(str(entry))\n",
    "                        if year>1800 and volume_count>1:\n",
    "                            records[year] = match_count\n",
    "\n",
    "                    #Modify the dictionary if new entry is already there, else just add it as a new unigram:records to the dict\n",
    "                    if unigram in ngram_dict.keys():\n",
    "                        #accessing the ngram dictionary and seeing if each year is present, if so add match count, else add a new record entry to the dictionary.\n",
    "                        for yr, match_ct in records.items(): #each record should be of the form {year, match_count}\n",
    "                            #If the year in the new record is in the dict for this 1gram, then find where it is.\n",
    "                            if yr in ngram_dict[unigram].keys():\n",
    "                                ngram_dict[unigram][yr] += match_ct\n",
    "                            else:\n",
    "                                #This just adds the record to the end, will need to sort later\n",
    "                                ngram_dict[unigram][yr] = match_ct\n",
    "                    else:\n",
    "                        ngram_dict[unigram] = records\n",
    "    \n",
    "    #Save as JSON\n",
    "    save_json(ngram_dict,directory,file_path[:-3]+'_CLOSED_CLASSES')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8977516a",
   "metadata": {},
   "source": [
    "## (2) Investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c6f5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(directory,file_path):\n",
    "    with open(directory+file_path,'r') as f:\n",
    "        ngrams = json.load(f)\n",
    "        f.close()\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28247f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(ngrams):\n",
    "    words = list(ngrams.keys())\n",
    "    years = [str(i) for i in range(1800,2020)]\n",
    "    unigram_dict = dict()\n",
    "    for word in tqdm(words):\n",
    "        match_count_by_year = []\n",
    "        for year in years:\n",
    "            if year in ngrams[word].keys():\n",
    "                match_count_by_year.append(ngrams[word][year])\n",
    "            else:\n",
    "                #Zeroes are necessary for smoothing\n",
    "                match_count_by_year.append(0)\n",
    "        unigram_dict[word] = match_count_by_year\n",
    "    \n",
    "    return unigram_dict, years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1acaa6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(unigram_dict, years,smoothing = 5):\n",
    "    df = pd.DataFrame.from_dict(unigram_dict #take in the dictionary\n",
    "                    ).rolling(smoothing,center=True #create frames of size 5 (smoothing value), and replace value in middle\n",
    "                    ).mean( #average accross those frames\n",
    "                    ).rename({i:years[i] for i in range(len(years))}, axis = 'index' #rename the indices to years\n",
    "                    ).dropna()\n",
    "    years_map = {i:int(year) for i, year in enumerate(df.index)}\n",
    "    ngrams = df.to_dict(orient = 'list')\n",
    "    return ngrams, years_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6fa4db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def birth_and_death(ngrams,years_map):\n",
    "    birth, death = {},{}\n",
    "    for unigram in tqdm(ngrams):\n",
    "        l = ngrams[unigram]\n",
    "        birth_years, death_years = [],[]\n",
    "        for i in range(len(l)-1):\n",
    "            #Birth\n",
    "            if l[i]==0 and l[i+1]!=0:\n",
    "                birth_years.append(years_map[i+1])\n",
    "            #Death\n",
    "            if l[i]!=0 and l[i+1]==0:\n",
    "                death_years.append(years_map[i])\n",
    "\n",
    "            #Disregarding death in the final year\n",
    "\n",
    "        if len(birth_years)>0:\n",
    "            birth[unigram] = birth_years\n",
    "\n",
    "        if len(death_years)>0:\n",
    "            death[unigram] = death_years\n",
    "\n",
    "    print('Birth:',len(birth),'\\nDeath:',len(death))\n",
    "    return birth, death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d8f3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate(directory,file_path):\n",
    "    #birth, death = birth_and_death(smoothing(normalize(open_json(directory,file_path))))\n",
    "    \n",
    "    ngrams = open_json(directory,file_path)\n",
    "    unigram_dict, years = normalize(ngrams)\n",
    "    del ngrams\n",
    "    ngrams, years_map = smoothing(unigram_dict, years)\n",
    "    del unigram_dict\n",
    "    del years\n",
    "    birth, death = birth_and_death(ngrams,years_map)\n",
    "    del ngrams\n",
    "    del years_map\n",
    "    save_json(birth,directory,file_path[:-5]+'_BIRTH')\n",
    "    save_json(death,directory,file_path[:-5]+'_DEATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078e1a7",
   "metadata": {},
   "source": [
    "## Run Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57c3721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './Ngrams/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a030e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2396510/2396510 [00:06<00:00, 350363.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00000-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3100658/3100658 [00:11<00:00, 280323.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00015-of-00024_CLOSED_CLASSES.json 13055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3109631/3109631 [00:10<00:00, 305724.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00009-of-00024_CLOSED_CLASSES.json 4368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3365531/3365531 [00:11<00:00, 281013.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00010-of-00024_CLOSED_CLASSES.json 12317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3467821/3467821 [00:13<00:00, 259971.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00022-of-00024_CLOSED_CLASSES.json 33454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3384057/3384057 [00:15<00:00, 221430.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00019-of-00024_CLOSED_CLASSES.json 72093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375570/3375570 [00:08<00:00, 405703.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00005-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3103866/3103866 [00:10<00:00, 307941.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00006-of-00024_CLOSED_CLASSES.json 16626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3071926/3071926 [00:12<00:00, 248594.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00021-of-00024_CLOSED_CLASSES.json 41723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3402459/3402459 [00:11<00:00, 302775.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00013-of-00024_CLOSED_CLASSES.json 3739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375649/3375649 [00:19<00:00, 170206.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00016-of-00024_CLOSED_CLASSES.json 123093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3081673/3081673 [00:08<00:00, 370738.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00003-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3377697/3377697 [00:09<00:00, 373982.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00004-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3118263/3118263 [00:14<00:00, 211875.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00018-of-00024_CLOSED_CLASSES.json 36568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4149670/4149670 [00:21<00:00, 191584.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00023-of-00024_CLOSED_CLASSES.json 122872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3386487/3386487 [00:12<00:00, 275977.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00011-of-00024_CLOSED_CLASSES.json 4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3408143/3408143 [00:10<00:00, 310660.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00008-of-00024_CLOSED_CLASSES.json 2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3392643/3392643 [00:14<00:00, 230260.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00014-of-00024_CLOSED_CLASSES.json 15740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3345476/3345476 [00:09<00:00, 343463.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00001-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3315859/3315859 [00:31<00:00, 104947.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram dict empty 1-00002-of-00024_CLOSED_CLASSES.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403219/3403219 [00:31<00:00, 109608.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00017-of-00024_CLOSED_CLASSES.json 20180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3135145/3135145 [00:10<00:00, 298056.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00012-of-00024_CLOSED_CLASSES.json 12206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3427775/3427775 [00:17<00:00, 200213.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00020-of-00024_CLOSED_CLASSES.json 77955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3384843/3384843 [00:12<00:00, 271381.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00007-of-00024_CLOSED_CLASSES.json 9092\n",
      "CPU times: user 10min 27s, sys: 1min 28s, total: 11min 56s\n",
      "Wall time: 12min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files = os.listdir(directory)\n",
    "for file_path in files:\n",
    "    if '.gz' in file_path:\n",
    "        preprocess_ngrams(directory,file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9f1ea8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33454/33454 [07:25<00:00, 75.13it/s]   \n",
      "100%|██████████| 33454/33454 [00:01<00:00, 28331.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 32801 \n",
      "Death: 31637\n",
      "SAVED:  1-00022-of-00024_CLOSED_CLASSES_BIRTH.json 32801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2891/2891 [00:00<00:00, 31859.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00022-of-00024_CLOSED_CLASSES_DEATH.json 31637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2891/2891 [00:00<00:00, 32852.34it/s]\n",
      "  0%|          | 0/16626 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 2848 \n",
      "Death: 2553\n",
      "SAVED:  1-00008-of-00024_CLOSED_CLASSES_BIRTH.json 2848\n",
      "SAVED:  1-00008-of-00024_CLOSED_CLASSES_DEATH.json 2553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16626/16626 [00:00<00:00, 29536.96it/s]\n",
      "100%|██████████| 16626/16626 [00:00<00:00, 31782.50it/s]\n",
      "  0%|          | 0/3739 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 16410 \n",
      "Death: 15352\n",
      "SAVED:  1-00006-of-00024_CLOSED_CLASSES_BIRTH.json 16410\n",
      "SAVED:  1-00006-of-00024_CLOSED_CLASSES_DEATH.json 15352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3739/3739 [00:00<00:00, 31047.33it/s]\n",
      "100%|██████████| 3739/3739 [00:00<00:00, 23591.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 3673 \n",
      "Death: 3386\n",
      "SAVED:  1-00013-of-00024_CLOSED_CLASSES_BIRTH.json 3673\n",
      "SAVED:  1-00013-of-00024_CLOSED_CLASSES_DEATH.json 3386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41723/41723 [00:01<00:00, 28121.77it/s]\n",
      "100%|██████████| 41723/41723 [00:01<00:00, 25363.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 40920 \n",
      "Death: 39239\n",
      "SAVED:  1-00021-of-00024_CLOSED_CLASSES_BIRTH.json 40920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/12317 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00021-of-00024_CLOSED_CLASSES_DEATH.json 39239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12317/12317 [00:00<00:00, 30507.55it/s]\n",
      "100%|██████████| 12317/12317 [00:00<00:00, 24559.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 12054 \n",
      "Death: 11014\n",
      "SAVED:  1-00010-of-00024_CLOSED_CLASSES_BIRTH.json 12054\n",
      "SAVED:  1-00010-of-00024_CLOSED_CLASSES_DEATH.json 11014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36568/36568 [00:01<00:00, 28902.21it/s]\n",
      "100%|██████████| 36568/36568 [00:01<00:00, 24760.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 35615 \n",
      "Death: 34482\n",
      "SAVED:  1-00018-of-00024_CLOSED_CLASSES_BIRTH.json 35615\n",
      "SAVED:  1-00018-of-00024_CLOSED_CLASSES_DEATH.json 34482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123093/123093 [00:04<00:00, 26986.00it/s]\n",
      "100%|██████████| 123093/123093 [00:04<00:00, 25892.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 120170 \n",
      "Death: 116331\n",
      "SAVED:  1-00016-of-00024_CLOSED_CLASSES_BIRTH.json 120170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13055 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00016-of-00024_CLOSED_CLASSES_DEATH.json 116331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13055/13055 [00:00<00:00, 30972.35it/s]\n",
      "100%|██████████| 13055/13055 [00:00<00:00, 27336.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 12783 \n",
      "Death: 11938\n",
      "SAVED:  1-00015-of-00024_CLOSED_CLASSES_BIRTH.json 12783\n",
      "SAVED:  1-00015-of-00024_CLOSED_CLASSES_DEATH.json 11938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15740/15740 [00:00<00:00, 30886.30it/s]\n",
      "100%|██████████| 15740/15740 [00:00<00:00, 31911.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 15418 \n",
      "Death: 14603\n",
      "SAVED:  1-00014-of-00024_CLOSED_CLASSES_BIRTH.json 15418\n",
      "SAVED:  1-00014-of-00024_CLOSED_CLASSES_DEATH.json 14603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20180/20180 [00:00<00:00, 29395.45it/s]\n",
      "100%|██████████| 20180/20180 [00:00<00:00, 27905.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 19793 \n",
      "Death: 19037\n",
      "SAVED:  1-00017-of-00024_CLOSED_CLASSES_BIRTH.json 19793\n",
      "SAVED:  1-00017-of-00024_CLOSED_CLASSES_DEATH.json 19037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72093/72093 [00:02<00:00, 28396.24it/s]\n",
      "100%|██████████| 72093/72093 [00:02<00:00, 24230.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 70117 \n",
      "Death: 68116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4995 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00019-of-00024_CLOSED_CLASSES_BIRTH.json 70117\n",
      "SAVED:  1-00019-of-00024_CLOSED_CLASSES_DEATH.json 68116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4995/4995 [00:00<00:00, 32030.90it/s]\n",
      "100%|██████████| 4995/4995 [00:00<00:00, 32678.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 4941 \n",
      "Death: 4469\n",
      "SAVED:  1-00011-of-00024_CLOSED_CLASSES_BIRTH.json 4941\n",
      "SAVED:  1-00011-of-00024_CLOSED_CLASSES_DEATH.json 4469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77955/77955 [00:02<00:00, 28650.48it/s]\n",
      "100%|██████████| 77955/77955 [00:02<00:00, 26408.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 76363 \n",
      "Death: 73355\n",
      "SAVED:  1-00020-of-00024_CLOSED_CLASSES_BIRTH.json 76363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/12206 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  1-00020-of-00024_CLOSED_CLASSES_DEATH.json 73355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12206/12206 [00:00<00:00, 29001.07it/s]\n",
      "100%|██████████| 12206/12206 [00:00<00:00, 30199.57it/s]\n",
      "  0%|          | 0/9092 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 12048 \n",
      "Death: 11039\n",
      "SAVED:  1-00012-of-00024_CLOSED_CLASSES_BIRTH.json 12048\n",
      "SAVED:  1-00012-of-00024_CLOSED_CLASSES_DEATH.json 11039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9092/9092 [00:00<00:00, 29648.27it/s]\n",
      "100%|██████████| 9092/9092 [00:00<00:00, 31448.68it/s]\n",
      "  0%|          | 0/4368 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 8955 \n",
      "Death: 8420\n",
      "SAVED:  1-00007-of-00024_CLOSED_CLASSES_BIRTH.json 8955\n",
      "SAVED:  1-00007-of-00024_CLOSED_CLASSES_DEATH.json 8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4368/4368 [00:00<00:00, 29291.08it/s]\n",
      "100%|██████████| 4368/4368 [00:00<00:00, 32340.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 4293 \n",
      "Death: 3945\n",
      "SAVED:  1-00009-of-00024_CLOSED_CLASSES_BIRTH.json 4293\n",
      "SAVED:  1-00009-of-00024_CLOSED_CLASSES_DEATH.json 3945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122872/122872 [00:04<00:00, 27815.97it/s]\n",
      "100%|██████████| 122872/122872 [00:04<00:00, 27492.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth: 118388 \n",
      "Death: 115411\n",
      "SAVED:  1-00023-of-00024_CLOSED_CLASSES_BIRTH.json 118388\n",
      "SAVED:  1-00023-of-00024_CLOSED_CLASSES_DEATH.json 115411\n",
      "CPU times: user 3min 10s, sys: 4min 20s, total: 7min 30s\n",
      "Wall time: 9min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files = os.listdir(directory)\n",
    "for file_path in files:\n",
    "    if '_CLOSED_CLASSES.json' in file_path:\n",
    "        investigate(directory,file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
