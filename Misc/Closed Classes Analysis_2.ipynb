{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8d7b92",
   "metadata": {},
   "source": [
    "# Goal: Investigate birth and death among closed classes of words\n",
    "1. Load the \\*\\_CLOSED_CLASSES.json files\n",
    "2. Separate the word from the part of speech and form JSON of form  \n",
    "        {unigram: {pos:'pos', \n",
    "                   birth_years:[year1, year2, ...],\n",
    "                   death_years:[year1, year2, ...]}\n",
    "            ...}\n",
    "3. Concatenate the final dictionaries\n",
    "4. Save as a single JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a193957a",
   "metadata": {},
   "source": [
    "Available parts of speech:\n",
    "- _PRON_\tpronoun\n",
    "- _DET_\tdeterminer or article\n",
    "- _ADP_\tan adposition: either a preposition or a postposition\n",
    "- _CONJ_\tconjunction\n",
    "- _PRT_\tparticle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2901e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb06cc9",
   "metadata": {},
   "source": [
    "## (1) Load the \\*\\_CLOSED_CLASSES.json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf7cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "#For the Google POS tagging\n",
    "underscore = re.compile('_{1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c6f5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(directory,file_path):\n",
    "    with open(directory+file_path,'r') as f:\n",
    "        ngrams = json.load(f)\n",
    "        f.close()\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9025211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(ngrams):\n",
    "    years = [str(i) for i in range(1800,2020)]\n",
    "    unigram_dict = dict()\n",
    "    for word in tqdm(ngrams.keys()):\n",
    "        match_count_by_year = []\n",
    "        for year in years:\n",
    "            if year in ngrams[word].keys():\n",
    "                match_count_by_year.append(ngrams[word][year])\n",
    "            else:\n",
    "                #Zeroes are necessary for smoothing\n",
    "                match_count_by_year.append(0)\n",
    "        unigram_dict[word] = match_count_by_year\n",
    "    return unigram_dict, years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d229b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(unigram_dict, years,smoothing = 5):\n",
    "    df = pd.DataFrame.from_dict(unigram_dict #take in the dictionary\n",
    "                    ).rolling(smoothing,center=True #create frames of size 5 (smoothing value), and replace value in middle\n",
    "                    ).mean( #average accross those frames\n",
    "                    ).rename({i:years[i] for i in range(len(years))}, axis = 'index' #rename the indices to years\n",
    "                    ).dropna()\n",
    "    years_map = {i:int(year) for i, year in enumerate(df.index)}\n",
    "    ngrams = df.to_dict(orient = 'list')\n",
    "    return ngrams, years_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6cb904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anaylze_birth_and_death(ngrams,years_map):\n",
    "    ngrams_analyzed = {}\n",
    "    \n",
    "    for unigram in tqdm(ngrams.keys()):\n",
    "        l = ngrams[unigram]\n",
    "        birth_years, death_years = [],[]\n",
    "        for i in range(len(l)-1):\n",
    "            #Birth\n",
    "            if l[i]==0 and l[i+1]!=0:\n",
    "                birth_years.append(years_map[i+1])\n",
    "            #Death\n",
    "            if l[i]!=0 and l[i+1]==0:\n",
    "                death_years.append(years_map[i])\n",
    "            #Disregarding death in the final year\n",
    "        if len(birth_years)+len(death_years)>0:\n",
    "            #Replace the \n",
    "            word_pos = underscore.split(unigram)\n",
    "            ngrams_analyzed[word_pos[0]] = {'POS':word_pos[1],\n",
    "                                            'birth_years':birth_years,\n",
    "                                            'death_years':death_years}\n",
    "    return ngrams_analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "849b81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(dictionary,directory,file_path):\n",
    "    output = file_path+'.json'\n",
    "    if len(dictionary)>0:\n",
    "        with open(directory+output, 'w') as f_out:\n",
    "            json.dump(dictionary, f_out)\n",
    "        print('SAVED: ',output,len(dictionary))\n",
    "    else:\n",
    "        print('unigram dict empty',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39341f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(directory):\n",
    "    final_dict = {}\n",
    "    \n",
    "    directory = './Ngrams/'\n",
    "    files = os.listdir(directory)\n",
    "    for file_path in files:\n",
    "        if '_CLOSED_CLASSES.json' in file_path:\n",
    "            ngrams = open_json(directory,file_path)\n",
    "            unigram_dict, years = normalize(ngrams)\n",
    "            del ngrams\n",
    "            ngrams, years_map = smoothing(unigram_dict, years)\n",
    "            del unigram_dict\n",
    "            del years\n",
    "            ngrams_analyzed = anaylze_birth_and_death(ngrams,years_map)\n",
    "            del ngrams\n",
    "            del years_map\n",
    "            final_dict.update(ngrams_analyzed)\n",
    "    save_json(final_dict,directory,'CLOSED_CLASSES_ANALYZED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078e1a7",
   "metadata": {},
   "source": [
    "## Run Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c3721f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33454/33454 [00:01<00:00, 24807.85it/s]\n",
      "100%|██████████| 33454/33454 [00:01<00:00, 27170.99it/s]\n",
      "100%|██████████| 2891/2891 [00:00<00:00, 29914.16it/s]\n",
      "100%|██████████| 2891/2891 [00:00<00:00, 26810.47it/s]\n",
      "100%|██████████| 16626/16626 [00:00<00:00, 26689.98it/s]\n",
      "100%|██████████| 16626/16626 [00:00<00:00, 23398.90it/s]\n",
      "100%|██████████| 3739/3739 [00:00<00:00, 28731.43it/s]\n",
      "100%|██████████| 3739/3739 [00:00<00:00, 28419.39it/s]\n",
      "100%|██████████| 41723/41723 [00:01<00:00, 27256.38it/s]\n",
      "100%|██████████| 41723/41723 [00:01<00:00, 25297.12it/s]\n",
      "100%|██████████| 12317/12317 [00:00<00:00, 17051.31it/s]\n",
      "100%|██████████| 12317/12317 [00:00<00:00, 21219.42it/s]\n",
      "100%|██████████| 36568/36568 [00:01<00:00, 28449.36it/s]\n",
      "100%|██████████| 36568/36568 [00:01<00:00, 25174.95it/s]\n",
      "100%|██████████| 123093/123093 [00:04<00:00, 26144.71it/s]\n",
      "100%|██████████| 123093/123093 [00:05<00:00, 21982.48it/s]\n",
      "100%|██████████| 13055/13055 [00:00<00:00, 28837.56it/s]\n",
      "100%|██████████| 13055/13055 [00:00<00:00, 16215.44it/s]\n",
      "100%|██████████| 15740/15740 [00:00<00:00, 25922.65it/s]\n",
      "100%|██████████| 15740/15740 [00:00<00:00, 26668.25it/s]\n",
      "100%|██████████| 20180/20180 [00:00<00:00, 27480.04it/s]\n",
      "100%|██████████| 20180/20180 [00:00<00:00, 28729.94it/s]\n",
      "100%|██████████| 72093/72093 [00:02<00:00, 24196.51it/s]\n",
      "100%|██████████| 72093/72093 [00:03<00:00, 23215.22it/s]\n",
      "100%|██████████| 4995/4995 [00:00<00:00, 28812.22it/s]\n",
      "100%|██████████| 4995/4995 [00:00<00:00, 22504.97it/s]\n",
      "100%|██████████| 77955/77955 [00:03<00:00, 21874.96it/s]\n",
      "100%|██████████| 77955/77955 [00:02<00:00, 28621.18it/s]\n",
      "100%|██████████| 12206/12206 [00:00<00:00, 28280.70it/s]\n",
      "100%|██████████| 12206/12206 [00:00<00:00, 27595.85it/s]\n",
      "100%|██████████| 9092/9092 [00:00<00:00, 28130.05it/s]\n",
      "100%|██████████| 9092/9092 [00:00<00:00, 27928.22it/s]\n",
      "100%|██████████| 4368/4368 [00:00<00:00, 30009.52it/s]\n",
      "100%|██████████| 4368/4368 [00:00<00:00, 28316.02it/s]\n",
      "100%|██████████| 122872/122872 [00:04<00:00, 27884.93it/s]\n",
      "100%|██████████| 122872/122872 [00:04<00:00, 29138.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED:  CLOSED_CLASSES_ANALYZED.json 440403\n",
      "CPU times: user 2min 47s, sys: 5 s, total: 2min 52s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "main(directory = './Ngrams/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
