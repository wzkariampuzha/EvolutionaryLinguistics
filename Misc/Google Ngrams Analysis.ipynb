{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals: \n",
    " - Take in filtered JSON files and output them to df and do analysis on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Ngrams/1-00015-of-00024-lemmatized.json', 'r') as f:\n",
    "    ngrams = json.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(ngrams.keys())\n",
    "years = [str(i) for i in range(1800,2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(directory,file_path):\n",
    "    with open(directory+file_path,'r') as f:\n",
    "        ngrams = json.load(f)\n",
    "        f.close()\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(ngrams):\n",
    "    words = list(ngrams.keys())\n",
    "    years = [str(i) for i in range(1800,2020)]\n",
    "    unigram_dict = dict()\n",
    "    i=0\n",
    "    for word in words:\n",
    "        match_count_by_year = []\n",
    "        for year in years:\n",
    "            if year in ngrams[word].keys():\n",
    "                match_count_by_year.append(ngrams[word][year])\n",
    "            else:\n",
    "                #Zeroes are necessary for smoothing\n",
    "                match_count_by_year.append(0)\n",
    "        unigram_dict[word] = match_count_by_year\n",
    "        del match_count_by_year\n",
    "        i+=1\n",
    "        if i%50000==0:\n",
    "            print(i)\n",
    "    \n",
    "    return unigram_dict, words, years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_and_smooth(unigram_dict, years):\n",
    "    return pd.DataFrame.from_dict(unigram_dict #take in the dictionary\n",
    "                ).rolling(5,center=True #create frames of size 5 (smoothing value), and replace value in middle\n",
    "                ).mean( #average accross those frames\n",
    "                ).rename({i:years[i] for i in range(len(years))}, axis = 'index' #rename the indices to years\n",
    "                ).dropna( #drop the edge years that were not averaged with 4 other rows\n",
    "                ).replace(to_replace=0, value=np.NaN) #replace all zeroes with NaN for the next iteration step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize list so that there are zeros for every year, which is necessary so that the lists are the same size and for smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "unigram_dict = {}\n",
    "for word in tqdm(words):\n",
    "    match_count_by_year = []\n",
    "    for year in years:\n",
    "        if year in ngrams[word].keys():\n",
    "            match_count_by_year.append(ngrams[word][year])\n",
    "        else:\n",
    "            #Zeroes are necessary for smoothing\n",
    "            match_count_by_year.append(0)\n",
    "    unigram_dict[word] = match_count_by_year\n",
    "    del match_count_by_year\n",
    "del ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.DataFrame.from_dict(unigram_dict #take in the dictionary\n",
    "                ).rolling(5,center=True #create frames of size 5 (smoothing value), and replace value in middle\n",
    "                ).mean( #average accross those frames\n",
    "                ).rename({i:years[i] for i in range(len(years))}, axis = 'index' #rename the indices to years\n",
    "                ).dropna() #drop the edge years that were not averaged with 4 other rows\n",
    "                #).replace(to_replace=0, value=np.NaN) #replace all zeroes with NaN for the next iteration step\n",
    "del years\n",
    "del unigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(unigram_dict)\n",
    "del unigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "years_map = {i:int(year) for i, year in enumerate(df.index)}\n",
    "ngrams_processed = df.to_dict(orient = 'list')\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "birth, death = {},{}\n",
    "for unigram in tqdm(ngrams_processed):\n",
    "    l = ngrams_processed[unigram]\n",
    "    birth_years, death_years = [],[]\n",
    "    for i in range(len(l)-1):\n",
    "        #Birth\n",
    "        if l[i]==0 and l[i+1]!=0:\n",
    "            birth_years.append(years_map[i+1])\n",
    "        #Death\n",
    "        if l[i]!=0 and l[i+1]==0:\n",
    "            death_years.append(years_map[i])\n",
    "    \n",
    "        #Disregarding death in the final year\n",
    "            \n",
    "    if len(birth_years)>0:\n",
    "        birth[unigram] = birth_years\n",
    "\n",
    "    if len(death_years)>0:\n",
    "        death[unigram] = death_years\n",
    "\n",
    "print(len(birth),len(death))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ngrams_processed['trichiulus']\n",
    "birth, death = {},{}\n",
    "birth_years, death_years = [],[]\n",
    "for i in range(len(l)-1):\n",
    "    #Birth\n",
    "    if l[i]==0 and l[i+1]!=0:\n",
    "        birth_years.append(years_map[i+1])\n",
    "    #Death\n",
    "    if l[i]!=0 and l[i+1]==0:\n",
    "        death_years.append(years_map[i])\n",
    "\n",
    "    #Disregarding death in the final year\n",
    "\n",
    "if len(birth_years)>0:\n",
    "    birth[word] = birth_years\n",
    "\n",
    "if len(death_years)>0:\n",
    "    death[word] = death_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(dictionary,directory,file_path):\n",
    "    output = file_path+'.json'\n",
    "    if len(dictionary)>0:\n",
    "        with open(directory+output, 'w') as f_out:\n",
    "            json.dump(ngram_dict, f_out)\n",
    "        print('SAVED: ',output,len(ngram_dict))\n",
    "    else:\n",
    "        print('unigram dict empty',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the words that birth and die into a dictionariess with the years of birth/death in separated lists\n",
    "birth,death = {},{}\n",
    "i=0\n",
    "for word in words:\n",
    "    #If there were zeroes in the series proceed, else skip \n",
    "    if df[word].hasnans:\n",
    "        print('good word',i)\n",
    "        birth_years, death_years = [],[]\n",
    "        \n",
    "        for idx, val in df[word].items():\n",
    "            print(idx,val,i)\n",
    "            if idx == df[word].index[len(df[word])-1]:\n",
    "                #Death\n",
    "                if not pd.isna(df[word].at[str(int(idx)-1)]) and pd.isna(df[word].at[idx]):\n",
    "                    death_years.append(int(idx)-1)\n",
    "\n",
    "            else:\n",
    "                #Birth\n",
    "                if pd.isna(df[word].at[idx]) and not pd.isna(df[word].at[str(int(idx)+1)]):\n",
    "                    print('birthed')\n",
    "                    birth_years.append(int(idx)+1)\n",
    "                \n",
    "                #Death\n",
    "                if not pd.isna(df[word].at[str(int(idx))]) and pd.isna(df[word].at[str(int(idx)+1)]):\n",
    "                    print('dead')\n",
    "                    death_years.append(int(idx))\n",
    "                \n",
    "        birth[word] = birth_years\n",
    "        death[word] = death_years\n",
    "    i+=1\n",
    "    if i%50000==0:\n",
    "        print(birth)\n",
    "        print(death)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unused Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate rolling average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ave=df.rolling(5,center=True).mean().rename({i:years[i] for i in range(len(years))}, axis = 'index').dropna().copy()\n",
    "del df\n",
    "del years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ave.tail(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for idx, val in df_ave['trichiulus'].items():\n",
    "    \n",
    "    if idx == df_ave['trichiulus'].index[len(df_ave['trichiulus'])-1]:\n",
    "        print(idx,val)\n",
    "        pass\n",
    "    else:\n",
    "        print(idx,val)\n",
    "        print('')\n",
    "        print('next',df_ave['trichiulus'].at[str(int(idx)+1)])\n",
    "        #if val: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_ave['trichiulus'])\n",
    "#Series.hasnans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['trichiulus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[word].at['2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(df[word].at['2015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[word].at['2015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['trichiulus'].index[len(df['trichiulus'])-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[index from integer location](https://stackoverflow.com/questions/17244049/finding-label-location-in-a-dataframe-index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in df_ave['trichiulus'].items():\n",
    "    \n",
    "    if idx == df_ave['trichiulus'].index[len(df_ave['trichiulus'])-1]:\n",
    "        print(idx,val)\n",
    "        pass\n",
    "    else:\n",
    "        print(idx,val)\n",
    "        print('')\n",
    "        print('next',df_ave['trichiulus'].at[str(int(idx)+1)],type(df_ave['trichiulus'].at[str(int(idx)+1)]))\n",
    "        #if val: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ave.replace(to_replace=0, value=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#working rename command for end\n",
    "df.rename({i:years[i] for i in range(len(years))}, axis = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ave=df.rolling(2,center=True,axis=1,closed='both').mean().copy()\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ave[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.iterrows():\n",
    "    print(row)\n",
    "    print(type(row))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './Ngrams/'\n",
    "files = os.listdir(directory)\n",
    "for file_path in files:\n",
    "    if '.gz' in file_path:\n",
    "        preprocess_ngrams(directory,file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
